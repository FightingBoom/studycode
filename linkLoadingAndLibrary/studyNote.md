# 第1部分 简介

## 第1章 温故而知新

### 1.1 从 Hello World 说起

从 Hello World 思考一些问题：

  ? 程序为什么要被编译器编译了之后才可以运行？

  ? 编译器在把C语言程序转换成可以执行的机器码的过程中做了什么，怎么做的？

  ? 最后编译出来的可执行文件里面是什么？除了机器码还有什么？它们怎么存放的，怎么组织的？

  ? #include <stdio.h>是什么意思？把stdio.h包含进来意味着什么？C语言库又是什么？它怎么实现的？

  ? 不同的编译器（Microsoft VC、GCC）和不同的硬件平台（x86、SPARC、MIPS、ARM），以及不同的操作系统（Windows、Linux、UNIX、Solaris），最终编译出来的结果一样吗？为什么？

  ? Hello World程序是怎么运行起来的？操作系统是怎么装载它的？它从哪儿开始执行，到哪儿结束？main函数之前发生了什么？main函数结束以后又发生了什么？

  ? 如果没有操作系统，Hello World可以运行吗？如果要在一台没有操作系统的机器上运行Hello World需要什么？应该怎么实现？

  ? printf是怎么实现的？它为什么可以有不定数量的参数？为什么它能够在终端上输出字符串？

  ? Hello World程序在运行时，它在内存中是什么样子的？



### 1.2 万变不离其宗

最为关键的三个部件：中央处理器 CPU 、内存和 I/O 控制芯片；



北桥（Northbridge，PCI Bridge）

南桥（Southbridge）



多核处理器（Multi-core Processor）

> “多处理器应用最多的场合也是这些商用的服务器和需要处理大量计算的环境。而在个人电脑中，使用多处理器则是比较奢侈的行为，毕竟多处理器的成本是很高的。于是处理器的厂商开始考虑将多个处理器“合并在一起打包出售”，这些“被打包”的处理器之间共享比较昂贵的缓存部件，只保留多个核心，并且以一个处理器的外包装进行出售，售价比单核心的处理器只贵了一点，这就是多核处理器（Multi-core Processor）的基本想法。”
>
> 摘录来自
> 程序员的自我修养：链接、装载与库
> 俞甲子 石凡 潘爱民
> 此材料可能受版权保护。



[Free Lunch is Over（免费午餐已经结束了）](http://www.gotw.ca/publications/concurrency-ddj.htm)



### 1.3 站得高，望得远

“Any problem in computer science can be solved by another layer of indirection.”

“计算机科学领域的任何问题都可以通过增加一个间接的中间层来解决”



### 1.4 操作系统做什么

操作系统的一个功能是提供抽象的接口，另外一个主要功能是管理硬件资源。

让计算机硬件发挥所有潜能。



#### 1.4.1 不要让 CPU 打盹

分时系统（Time-Sharing System）



多任务（Multi-tasking）系统，操作系统接管了所有的硬件资源，并且本身运行在一个受硬件保护的级别。所有的应用程序都以进程（Process）的方式运行在比操作系统权限更低的级别，每个进程都有自己独立的地址空间，使得进程之间的地址空间相互隔离。CPU由操作系统统一进行分配，每个进程根据进程优先级的高低都有机会得到CPU，但是，如果运行时间超出了一定的时间，操作系统会暂停该进程，将CPU资源分配给其他等待运行的进程。这种CPU的分配方式即所谓的抢占式（Preemptive），操作系统可以强制剥夺CPU资源并且分配给它认为目前最需要的进程。如果操作系统分配给每个进程的时间都很短，即CPU在多个进程间快速地切换，从而造成了很多进程都在同时运行的假象。



#### 1.4.2 设备驱动

“DDA（一种画直线的图形算法）”

“硬件驱动（Device Driver）”

“现代的硬盘普遍使用一种叫做LBA（Logical Block Address）的方式，即整个硬盘中所有的扇区从0开始编号，一直到最后一个扇区，这个扇区编号叫做逻辑扇区号。”



### 1.5 内存不够怎么办

“? 地址空间不隔离 所有程序都直接访问物理地址，程序所使用的内存空间不是相互隔离的。”



“? 内存使用效率低 由于没有有效的内存管理机制，通常需要一个程序执行时，监控程序就将整个程序装入内存中然后开始执行。”



“? 程序运行的地址不确定 因为程序每次需要装入运行时，我们都需要给它从内存中分配一块足够大的空闲区域，这个空闲区域的位置是不确定的。”



#### 1.5.1 关于隔离

“地址空间分两种：虚拟地址空间（Virtual Address Space）和物理地址空间（Physical Address Space）。”



“物理地址空间是实实在在存在的，存在于计算机中，而且对于每一台计算机来说只有唯一的一个。”



“虚拟地址空间是指虚拟的、人们想象出来的地址空间，其实它并不存在，每个进程都有自己独立的虚拟空间，而且每个进程只能访问自己的地址空间，这样就有效地做到了进程的隔离。”



#### 1.5.2 分段（Segmentation）

“基本思路是把一段与程序所需要的内存空间大小的虚拟空间映射到某个地址空间。”



“根据程序的局部性原理，当一个程序在运行时，在某个时间段内，它只是频繁地用到了一小部分数据，也就是说，程序的很多数据其实在一个时间段内都是不会被用到的。人们很自然地想到了更小粒度的内存分割和映射的方法，使得程序的局部性原理得到充分的利用，大大提高了内存的使用率。这种方法就是分页（Paging）。”



#### 1.5.3 分页（Paging）

“我们把虚拟空间的页就叫虚拟页（VP，Virtual Page），把物理内存中的页叫做物理页（PP，Physical Page），把磁盘中的页叫做磁盘页（DP，Disk Page）。”



“MMU（Memory Management Unit）”



### 1.6 众人拾柴火焰高

#### 1.6.1 线程基础

“线程（Thread），有时被称为轻量级进程（Lightweight Process, LWP），是程序执行流的最小单元。一个标准的线程由线程ID、当前指令指针（PC）、寄存器集合和堆栈组成。通常意义上，一个进程由一个到多个线程组成，各个线程之间共享程序的内存空间（包括代码段、数据段、堆等）及一些进程级的资源（如打开文件和信号）。”



通常，使用多线程的原因有如下几点：

- 某个操作可能会陷入长时间等待，等待的线程会进入睡眠状态，无法继续执行。
- 某个操作（常常是计算）会消耗大量的时间，如果只有一个线程，程序和用户之间的交互会中断。多线程可以让一个线程负责交互，另一个线程负责计算。
- 程序逻辑本身就要求并发操作
- 多CPU或多核计算机（基本就是未来的主流计算机），本身具备同时执行多个线程的能力，因此单线程程序无法全面地发挥计算机的全部计算能力。
- 相对于多进程应用，多线程在数据共享方面效率要高很多。




**线程调度与优先级**

这样的一个不断在处理器上切换不同的线程的行为称之为线程调度（Thread Schedule）。在线程调度中，线程通常拥有至少三种状态，分别是：

- 运行（Running）：此时线程正在执行。
- 就绪（Ready）：此时线程可以立刻运行，但CPU已经被占用。
- 等待（Waiting）：此时线程正在等待某一事件（通常是I/O或同步）发生，无法执行。



我们一般把频繁等待的线程称之为IO密集型线程（IO Bound Thread），而把很少等待的线程称为CPU密集型线程（CPU Bound Thread）。IO密集型线程总是比CPU密集型线程容易得到优先级的提升。



在优先级调度的环境下，线程的优先级改变一般有三种方式。

- 用户指定优先级。
- 根据进入等待状态的频繁程度提升或降低优先级。
- 长时间得不到执行而被提升优先级。



**可抢占线程和不可抢占线程**

线程在用尽时间片之后会被强制剥夺继续执行的权利，而进入就绪状态，这个过程叫做抢占（Preemption）



fork ，复制当前进程

exec ，使用新的可执行映像覆盖当前可执行映像

clone ，创建子进程并从指定位置开始执行



fork产生新任务的速度非常快，因为fork并不复制原任务的内存空间，而是和原任务一起共享一个写时复制（Copy on Write, COW）的内存空间（见图1-10）。所谓写时复制，指的是两个任务可以同时自由地读取内存，但任意一个任务试图对内存进行修改时，内存就会复制一份提供给修改方单独使用，以免影响到其他的任务使用。



#### 1.6.2 线程安全

**竞争与原子操作**

多个线程同时访问一个共享数据，可能会造成很恶劣的后果。



自增（++）操作在多线程环境下会出现错误是因为这个操作被编译为汇编代码之后不止一条指令，因此在执行的时候可能执行了一半就被调度系统打断，去执行别的代码。我们把单指令的操作称为原子的（Atomic）



**同步与锁**

二元信号量（Binary Semaphore）是最简单的一种锁，只有两种状态：占用与非占用。



多元信号量简称信号量（Semaphore），它是一个很好的选择。一个初始值为N的信号量允许N个线程并发访问。

- 同一个信号量可以被系统中的一个线程获取之后由另一个线程释放；
- 任何进程可见



互斥量（Mutex）

- 要求哪个线程获取了互斥量，哪个线程就要负责释放这个锁；
- 任何进程可见；



临界区（Critical Section）是比互斥量更严格的同步手段。

临界区和互斥量与信号量的区别在于，互斥量和信号量在系统的任何进程里都是可见的，也就是说，一个进程创建了一个互斥量或信号量，另一个进程试图去获取该锁是合法的。然而，临界区的作用范围仅限于本进程，其他的进程无法获取该锁。除此之外，临界区具有和互斥量相同的性质。



读写锁（Read-Write Lock）。如上几种方式，对于读取频繁，而仅仅偶尔写入的情况，会显得非常低效。

| 读写锁状态 | 以共享方式获取 | 以独占方式获取 |
| :--------: | :------------: | :------------: |
|    自由    |      成功      |      成功      |
|    共享    |      成功      |      等待      |
|    独占    |      等待      |      等待      |



条件变量（Condition Variable）

对于条件变量，线程可以有两种操作，首先线程可以等待条件变量，一个条件变量可以被多个线程等待。其次，线程可以唤醒条件变量，此时某个或所有等待此条件变量的线程都会被唤醒并继续支持。也就是说，使用条件变量可以让许多线程一起等待某个事件的发生，当事件发生时（条件变量被唤醒），所有的线程可以一起恢复执行。



**可重入（Reentrant）与线程安全**

一个函数被重入，表示这个函数没有执行完成，由于外部因素或内部调用，又一次进入该函数执行。一个函数要被重入，只有两种情况：

（1）多个线程同时执行这个函数。

（2）函数自身（可能是经过多层调用之后）调用自身。



可重入是并发安全的强力保障，一个可重入的函数可以在多线程环境下放心使用。



**过度优化**

我们可以使用volatile关键字试图阻止过度优化，volatile基本可以做到两件事情：

（1）阻止编译器为了提高速度将一个变量缓存到寄存器内而不写回。

（2）阻止编译器调整操作volatile变量的指令顺序。



通常情况下是调用CPU提供的一条指令，这条指令常常被称为barrier。一条barrier指令会阻止CPU将该指令之前的指令交换到barrier之后，反之亦然。换句话说，barrier指令的作用类似于一个拦水坝，阻止换序“穿透”这个大坝。

```c++
#define barrier() __asm__ volatile (”lwsync”)


volatile T* pInst = 0;
T* GetInstance()
{
    if (!pInst)
    {
        lock();
        if (!pInst)
        {
            T* temp = new T;
            barrier(); // 确保对象构造在此之前执行
            pInst = temp;
        }
        unlock();
    }
    return pInst;
}
```



#### 1.6.3 多线程内部情况

**三种线程模型**

用户态线程并不一定在操作系统内核里对应同等数量的内核线程。



1. 一对一模型

对一对一模型来说，一个用户使用的线程就唯一对应一个内核使用的线程（但反过来不一定，一个内核里的线程在用户态不一定有对应的线程存在）

此时，线程之间的并发是真正的并发，一个线程阻塞，其他线程不会受影响。

缺点：

- 数量有限制；
- 内核线程调度，上下文切换开销较大，导致执行效率下降；



2. 多对一模型

多对一模型将多个用户线程映射到一个内核线程上，线程之间的切换由用户态的代码来进行，因此相对于一对一模型，多对一模型的线程切换要快速许多。



缺点：

- 有一个用户线程阻塞，所有线程都将无法执行。



3. 多对多模型

将多个用户线程映射到少数但不止一个内核线程上。



### 1.7 本章小结

对计算机的软硬件基本结构进行了回顾。



# 第2部分 静态链接

## 第2章 编译和链接

### 2.1 被隐藏了的过程

一个简单的 hello world 程序，在 gcc 编译的时候，包含：预处理（ Prepressing ）、编译（Compilation）、汇编（Assembly）和链接（Linking）。

![image-20240926225744315](https://cdn.jsdelivr.net/gh/FightingBoom/AllPicture@master/img/202409262257508.png)



#### 2.1.1 预编译

预编译过程主要处理代码中以 “#” 开始的预编译指令。比如 `#include` 、`#define` 等，主要处理规则如下：

- 将所有的 `#define` 删除，并且展开所有的宏定义。
- 处理所有条件预编译指令，比如“#if”、“#ifdef”、“#elif”、“#else”、“#endif”。
- 处理“#include”预编译指令，将被包含的文件插入到该预编译指令的位置。注意，这个过程是递归进行的，也就是说被包含的文件可能还包含其他文件。
- 删除所有的注释“//”和“/* */”。
- 添加行号和文件名标识，比如#2“hello.c”2，以便于编译时编译器产生调试用的行号信息及用于编译时产生编译错误或警告时能够显示行号。
- 保留所有的#pragma编译器指令，因为编译器须要使用它们。



> 经过预编译后的.i文件不包含任何宏定义，因为所有的宏已经被展开，并且包含的文件也已经被插入到.i文件中。所以当我们无法判断宏定义是否正确或头文件包含是否正确时，可以查看预编译后的文件来确定问题。
>



#### 2.1.2 编译

编译过程就是把预处理完的文件进行一系列词法分析、语法分析、语义分析及优化后生产相应的汇编代码文件，这个过程往往是我们所说的整个程序构建的核心部分，也是最复杂的部分之一。



现代版本的 GCC 把预编译和编译两个步骤合并成一个步骤，用 cc1 来实现。



#### 2.1.3 汇编

汇编器 as 。

```shell
as hello.s -o hello.o
```



#### 2.1.4 链接

```shell
$ld -static /usr/lib/crt1.o /usr/lib/crti.o /usr/lib/gcc/i486-linux-gnu/4.1.3/crtbeginT.o -L/usr/lib/gcc/i486-linux-gnu/4.1.3 -L/usr/lib -L/lib hello.o --start-group -lgcc -lgcc_eh -lc --end-group /usr/lib/gcc/i486-linux-gnu/4.1.3/crtend.o /usr/lib/crtn.o
```





















