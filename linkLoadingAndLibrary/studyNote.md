# 第1部分 简介

## 第1章 温故而知新

### 1.1 从 Hello World 说起

从 Hello World 思考一些问题：

  ? 程序为什么要被编译器编译了之后才可以运行？

  ? 编译器在把C语言程序转换成可以执行的机器码的过程中做了什么，怎么做的？

  ? 最后编译出来的可执行文件里面是什么？除了机器码还有什么？它们怎么存放的，怎么组织的？

  ? #include <stdio.h>是什么意思？把stdio.h包含进来意味着什么？C语言库又是什么？它怎么实现的？

  ? 不同的编译器（Microsoft VC、GCC）和不同的硬件平台（x86、SPARC、MIPS、ARM），以及不同的操作系统（Windows、Linux、UNIX、Solaris），最终编译出来的结果一样吗？为什么？

  ? Hello World程序是怎么运行起来的？操作系统是怎么装载它的？它从哪儿开始执行，到哪儿结束？main函数之前发生了什么？main函数结束以后又发生了什么？

  ? 如果没有操作系统，Hello World可以运行吗？如果要在一台没有操作系统的机器上运行Hello World需要什么？应该怎么实现？

  ? printf是怎么实现的？它为什么可以有不定数量的参数？为什么它能够在终端上输出字符串？

  ? Hello World程序在运行时，它在内存中是什么样子的？



### 1.2 万变不离其宗

最为关键的三个部件：中央处理器 CPU 、内存和 I/O 控制芯片；



北桥（Northbridge，PCI Bridge）

南桥（Southbridge）



多核处理器（Multi-core Processor）

> “多处理器应用最多的场合也是这些商用的服务器和需要处理大量计算的环境。而在个人电脑中，使用多处理器则是比较奢侈的行为，毕竟多处理器的成本是很高的。于是处理器的厂商开始考虑将多个处理器“合并在一起打包出售”，这些“被打包”的处理器之间共享比较昂贵的缓存部件，只保留多个核心，并且以一个处理器的外包装进行出售，售价比单核心的处理器只贵了一点，这就是多核处理器（Multi-core Processor）的基本想法。”
>
> 摘录来自
> 程序员的自我修养：链接、装载与库
> 俞甲子 石凡 潘爱民
> 此材料可能受版权保护。



[Free Lunch is Over（免费午餐已经结束了）](http://www.gotw.ca/publications/concurrency-ddj.htm)



### 1.3 站得高，望得远

“Any problem in computer science can be solved by another layer of indirection.”

“计算机科学领域的任何问题都可以通过增加一个间接的中间层来解决”



### 1.4 操作系统做什么

操作系统的一个功能是提供抽象的接口，另外一个主要功能是管理硬件资源。

让计算机硬件发挥所有潜能。



#### 1.4.1 不要让 CPU 打盹

分时系统（Time-Sharing System）



多任务（Multi-tasking）系统，操作系统接管了所有的硬件资源，并且本身运行在一个受硬件保护的级别。所有的应用程序都以进程（Process）的方式运行在比操作系统权限更低的级别，每个进程都有自己独立的地址空间，使得进程之间的地址空间相互隔离。CPU由操作系统统一进行分配，每个进程根据进程优先级的高低都有机会得到CPU，但是，如果运行时间超出了一定的时间，操作系统会暂停该进程，将CPU资源分配给其他等待运行的进程。这种CPU的分配方式即所谓的抢占式（Preemptive），操作系统可以强制剥夺CPU资源并且分配给它认为目前最需要的进程。如果操作系统分配给每个进程的时间都很短，即CPU在多个进程间快速地切换，从而造成了很多进程都在同时运行的假象。



#### 1.4.2 设备驱动

“DDA（一种画直线的图形算法）”

“硬件驱动（Device Driver）”

“现代的硬盘普遍使用一种叫做LBA（Logical Block Address）的方式，即整个硬盘中所有的扇区从0开始编号，一直到最后一个扇区，这个扇区编号叫做逻辑扇区号。”



### 1.5 内存不够怎么办

“? 地址空间不隔离 所有程序都直接访问物理地址，程序所使用的内存空间不是相互隔离的。”



“? 内存使用效率低 由于没有有效的内存管理机制，通常需要一个程序执行时，监控程序就将整个程序装入内存中然后开始执行。”



“? 程序运行的地址不确定 因为程序每次需要装入运行时，我们都需要给它从内存中分配一块足够大的空闲区域，这个空闲区域的位置是不确定的。”



#### 1.5.1 关于隔离

“地址空间分两种：虚拟地址空间（Virtual Address Space）和物理地址空间（Physical Address Space）。”



“物理地址空间是实实在在存在的，存在于计算机中，而且对于每一台计算机来说只有唯一的一个。”



“虚拟地址空间是指虚拟的、人们想象出来的地址空间，其实它并不存在，每个进程都有自己独立的虚拟空间，而且每个进程只能访问自己的地址空间，这样就有效地做到了进程的隔离。”



#### 1.5.2 分段（Segmentation）

“基本思路是把一段与程序所需要的内存空间大小的虚拟空间映射到某个地址空间。”



“根据程序的局部性原理，当一个程序在运行时，在某个时间段内，它只是频繁地用到了一小部分数据，也就是说，程序的很多数据其实在一个时间段内都是不会被用到的。人们很自然地想到了更小粒度的内存分割和映射的方法，使得程序的局部性原理得到充分的利用，大大提高了内存的使用率。这种方法就是分页（Paging）。”



#### 1.5.3 分页（Paging）

“我们把虚拟空间的页就叫虚拟页（VP，Virtual Page），把物理内存中的页叫做物理页（PP，Physical Page），把磁盘中的页叫做磁盘页（DP，Disk Page）。”



“MMU（Memory Management Unit）”



### 1.6 众人拾柴火焰高

#### 1.6.1 线程基础

“线程（Thread），有时被称为轻量级进程（Lightweight Process, LWP），是程序执行流的最小单元。一个标准的线程由线程ID、当前指令指针（PC）、寄存器集合和堆栈组成。通常意义上，一个进程由一个到多个线程组成，各个线程之间共享程序的内存空间（包括代码段、数据段、堆等）及一些进程级的资源（如打开文件和信号）。”



通常，使用多线程的原因有如下几点：

- 某个操作可能会陷入长时间等待，等待的线程会进入睡眠状态，无法继续执行。
- 某个操作（常常是计算）会消耗大量的时间，如果只有一个线程，程序和用户之间的交互会中断。多线程可以让一个线程负责交互，另一个线程负责计算。
- 程序逻辑本身就要求并发操作
- 多CPU或多核计算机（基本就是未来的主流计算机），本身具备同时执行多个线程的能力，因此单线程程序无法全面地发挥计算机的全部计算能力。
- 相对于多进程应用，多线程在数据共享方面效率要高很多。




**线程调度与优先级**

这样的一个不断在处理器上切换不同的线程的行为称之为线程调度（Thread Schedule）。在线程调度中，线程通常拥有至少三种状态，分别是：

- 运行（Running）：此时线程正在执行。
- 就绪（Ready）：此时线程可以立刻运行，但CPU已经被占用。
- 等待（Waiting）：此时线程正在等待某一事件（通常是I/O或同步）发生，无法执行。



我们一般把频繁等待的线程称之为IO密集型线程（IO Bound Thread），而把很少等待的线程称为CPU密集型线程（CPU Bound Thread）。IO密集型线程总是比CPU密集型线程容易得到优先级的提升。



在优先级调度的环境下，线程的优先级改变一般有三种方式。

- 用户指定优先级。
- 根据进入等待状态的频繁程度提升或降低优先级。
- 长时间得不到执行而被提升优先级。



**可抢占线程和不可抢占线程**

线程在用尽时间片之后会被强制剥夺继续执行的权利，而进入就绪状态，这个过程叫做抢占（Preemption）



fork ，复制当前进程

exec ，使用新的可执行映像覆盖当前可执行映像

clone ，创建子进程并从指定位置开始执行



fork产生新任务的速度非常快，因为fork并不复制原任务的内存空间，而是和原任务一起共享一个写时复制（Copy on Write, COW）的内存空间（见图1-10）。所谓写时复制，指的是两个任务可以同时自由地读取内存，但任意一个任务试图对内存进行修改时，内存就会复制一份提供给修改方单独使用，以免影响到其他的任务使用。













